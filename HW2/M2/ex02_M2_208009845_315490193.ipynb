{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61b88ca7",
      "metadata": {
        "id": "61b88ca7"
      },
      "source": [
        "# Correlation Power Analysis\n",
        "Submitters:\n",
        "1. Chen Frydman 208009845\n",
        "2. Hadi Shaheen 315490193"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c675fe2e",
      "metadata": {
        "id": "c675fe2e"
      },
      "source": [
        "```bash\n",
        "docker pull annakul1/attacks_on_implementations:Assignment2\n",
        "docker run -p 80:8080 annakul1/attacks_on_implementations:Assignment2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e464ae3a",
      "metadata": {
        "id": "e464ae3a"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "795af469",
      "metadata": {
        "id": "795af469"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "536b7e83",
      "metadata": {
        "id": "536b7e83"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b09528",
      "metadata": {
        "id": "01b09528",
        "outputId": "ee5eaf11-d15c-4362-8302-e6d45d7b184a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "256\n",
            "http://aoi-assignment2.oy.ne.ro:8080/encrypt?user=208009845&difficulty=1\n"
          ]
        }
      ],
      "source": [
        "USER = 208009845\n",
        "DIFFICULTY = 1\n",
        "BASE_URL = \"aoi-assignment2.oy.ne.ro\"\n",
        "MAX_PLAINTEXT_LENGTH = 32\n",
        "MAX_KEY_LENGTHH = 32\n",
        "AMOUNT_OF_TRACES = 10000\n",
        "TIME_LIMIT = 10 * 60 # 10 minutes in seconds\n",
        "DIFFICULTY_TO_DOWNLOAD = 1\n",
        "KEY_LENGTH = 16\n",
        "PREFIX_TRACES_FILE_NAME = f\"traces_{USER}\"\n",
        "PREFIX_PLAINTEXT_FILE_NAME = f\"plaintext_{USER}\"\n",
        "PREFIX_ENCRYPT_URL = rf\"http://{BASE_URL}:8080/encrypt?user={USER}\"\n",
        "PREFIX_VERIFY_URL = rf\"http://{BASE_URL}:8080/verify?user={USER}\"\n",
        "\n",
        "AesSbox = [\n",
        "    0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5,0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76,\n",
        "    0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0,0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0,\n",
        "    0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc,0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15,\n",
        "    0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a,0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75,\n",
        "    0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0,0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84,\n",
        "    0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b,0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf,\n",
        "    0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85,0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8,\n",
        "    0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5,0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2,\n",
        "    0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17,0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73,\n",
        "    0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88,0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb,\n",
        "    0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c,0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79,\n",
        "    0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9,0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08,\n",
        "    0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6,0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a,\n",
        "    0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e,0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e,\n",
        "    0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94,0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf,\n",
        "    0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68,0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16\n",
        "]\n",
        "\n",
        "print(f\"{PREFIX_ENCRYPT_URL}&difficulty={DIFFICULTY}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Crack the key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ddd28d0",
      "metadata": {
        "id": "0ddd28d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_power_traces(\n",
        "    prefix_traces_filename: str = PREFIX_TRACES_FILE_NAME,\n",
        "    prefix_plaintext_filename: str = PREFIX_PLAINTEXT_FILE_NAME,\n",
        "    serverURL: str = PREFIX_ENCRYPT_URL,\n",
        "    number_of_power_traces: int = AMOUNT_OF_TRACES,\n",
        "    difficulty: int = DIFFICULTY\n",
        "):\n",
        "    \"\"\"\n",
        "    Downloads power traces and corresponding plaintexts from the remote server and saves them to files.\n",
        "\n",
        "    Args:\n",
        "        prefix_traces_filename (str): Prefix for the power traces file name.\n",
        "        prefix_plaintext_filename (str): Prefix for the plaintexts file name.\n",
        "        serverURL (str): The base URL of the encryption server.\n",
        "        number_of_power_traces (int): Number of power traces to download.\n",
        "        difficulty (int): The difficulty level for the challenge.\n",
        "\n",
        "    Saves:\n",
        "        - Power traces to 'files/{prefix_traces_filename}_{difficulty}_{number_of_power_traces}.txt'\n",
        "        - Plaintexts to 'files/{prefix_plaintext_filename}_{difficulty}_{number_of_power_traces}.txt'\n",
        "    \"\"\"\n",
        "    os.makedirs(\"files\", exist_ok=True)\n",
        "    traces_filename = f\"{prefix_traces_filename}_{difficulty}_{number_of_power_traces}.txt\"\n",
        "    traces_filepath = os.path.join(\"files\", traces_filename)\n",
        "    if os.path.exists(traces_filepath):\n",
        "        print(f\"{traces_filepath} already exists. Skipping download.\")\n",
        "        return\n",
        "\n",
        "    plaintext_filename = f\"{prefix_plaintext_filename}_{difficulty}_{number_of_power_traces}.txt\"\n",
        "    plaintext_filepath = os.path.join(\"files\", plaintext_filename)\n",
        "    if os.path.exists(plaintext_filepath):\n",
        "        print(f\"{plaintext_filepath} already exists. Skipping download.\")\n",
        "        return\n",
        "\n",
        "    with open(plaintext_filepath, \"w\") as plaintext_file, open(traces_filepath, \"w\") as traces_file:\n",
        "        url = f\"{serverURL}&difficulty={difficulty}\"\n",
        "        print(url)\n",
        "        for _ in range(number_of_power_traces):\n",
        "            resp = requests.get(url)\n",
        "            data = resp.json()\n",
        "            plaintext = data[\"plaintext\"]\n",
        "            plaintext_file.write(\"\".join(map(str, plaintext)) + \"\\n\")\n",
        "            leaks = data[\"leaks\"]\n",
        "            traces_file.write(\" \".join(map(str, leaks)) + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def getMeansVariances(filename: str):\n",
        "    \"\"\"\n",
        "    Reads the file containing saved power traces and calculates the mean and variance\n",
        "    of each position in the trace.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The name of the file containing the saved power traces.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two lists:\n",
        "            - means (list): A list of means for each position in the trace.\n",
        "            - variances (list): A list of variances for each position in the trace.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        raise FileNotFoundError(f\"{filename} does not exist. Please download the power traces first.\")\n",
        "\n",
        "    data = np.loadtxt(filename)\n",
        "    means = np.mean(data, axis=0)\n",
        "    variances = np.var(data, axis=0)\n",
        "    print(\"Mean\\tVariance\")\n",
        "    for m, v in zip(means, variances):\n",
        "        print(f\"{m}\\t{v}\")\n",
        "    return means.tolist(), variances.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hamming_weight(n):\n",
        "    \"\"\"Calculates the Hamming weight of an integer.\"\"\"\n",
        "    return bin(n).count('1')\n",
        "\n",
        "def find_key(plaintext_filename, traces_filename, amount_of_traces: int = AMOUNT_OF_TRACES, key_length: int = KEY_LENGTH): # Modified signature to take filename\n",
        "    # Load plaintexts from plaintext_filename\n",
        "    plaintexts = []\n",
        "    with open(plaintext_filename, 'r') as pf:\n",
        "        # Changed this line to parse plaintexts as hexadecimal integers\n",
        "        plaintexts = [[int(byte, 16) for byte in line.strip().split()] for line in pf]\n",
        "    \n",
        "    # Load power traces from traces_filename\n",
        "    power_traces = []\n",
        "    with open(traces_filename, 'r') as tf:\n",
        "        # Changed this line to parse power traces as floats\n",
        "        power_traces = [[float(val) for val in line.strip().split()] for line in tf]\n",
        "    if not power_traces or not plaintexts:\n",
        "        raise ValueError(\"Power traces or plaintexts are empty. Please check the input files.\")\n",
        "    \n",
        "    # Initialize best correlations and predicted key\n",
        "    best_correlations = [0.0] * KEY_LENGTH\n",
        "    found_key_bytes = [0] * KEY_LENGTH\n",
        "\n",
        "    # Iterate through each byte of the AES key (16 bytes)\n",
        "    for byte_index in range(key_length):\n",
        "        max_correlation = -1.0 # Store the maximum correlation for this byte\n",
        "        best_key_guess = 0 # Store the key guess that gave the max correlation\n",
        "\n",
        "        # Iterate through all possible key byte guesses (0-255)\n",
        "        for guess_k in range(256):\n",
        "            # Predicted Hamming weights for this key byte guess across all traces\n",
        "            predicted_ham_weights = []\n",
        "            for i in range(amount_of_traces):\n",
        "                # Calculate the intermediate value: P[byte_index] XOR guess_k\n",
        "                intermediate_val = plaintexts[i][byte_index] ^ guess_k\n",
        "                \n",
        "                # Apply S-box (first round output)\n",
        "                sbox_output = AesSbox[intermediate_val] # cite: 96, 97, 98\n",
        "                \n",
        "                # Calculate Hamming Weight\n",
        "                predicted_ham_weights.append(hamming_weight(sbox_output))\n",
        "\n",
        "            # Reshape power traces for correlation calculation\n",
        "            # You need to decide which part of the trace corresponds to Sbox output.\n",
        "            # The assignment states \"32 interesting positions: 16 contain HW(P^k), and 16 contain HW(S[P^K])\" \n",
        "            # This implies you need to find the correct 16 trace points corresponding to S[P^K].\n",
        "            # For simplicity, let's assume we test all trace points and pick the best one for correlation.\n",
        "            # In a real attack, you'd analyze the power trace to find these specific points.\n",
        "            \n",
        "            # To perform correlation, you need the actual power trace values for each trace.\n",
        "            # The 'means' and 'variances' lists are for the *entire* trace.\n",
        "            # You need to correlate 'predicted_ham_weights' with a *specific point* in the traces.\n",
        "            # The assignment hints at \"32 interesting positions\".\n",
        "            # You'll likely need to iterate through these 32 positions or all positions to find the highest correlation.\n",
        "\n",
        "            current_trace_point_correlations = []\n",
        "            for trace_point_idx in range(amount_of_traces): # Iterate through all measurement points in a trace\n",
        "                # Extract the power values for this specific trace_point_idx across all traces\n",
        "                actual_power_values_at_point = [trace[trace_point_idx] for trace in power_traces]\n",
        "\n",
        "                if np.std(actual_power_values_at_point) == 0 or np.std(predicted_ham_weights) == 0:\n",
        "                    correlation = 0 # Avoid division by zero if there's no variance\n",
        "                else:\n",
        "                    correlation = np.corrcoef(predicted_ham_weights, actual_power_values_at_point)[0, 1]\n",
        "                \n",
        "                current_trace_point_correlations.append(abs(correlation))\n",
        "\n",
        "            # Find the maximum correlation for this key guess across all trace points\n",
        "            max_corr_for_guess = np.max(current_trace_point_correlations)\n",
        "\n",
        "            if max_corr_for_guess > max_correlation:\n",
        "                max_correlation = max_corr_for_guess\n",
        "                best_key_guess = guess_k\n",
        "        \n",
        "        found_key_bytes[byte_index] = best_key_guess\n",
        "        best_correlations[byte_index] = max_correlation\n",
        "        print(f\"Byte {byte_index}: Best guess = {hex(best_key_guess)}, Max correlation = {max_correlation}\")\n",
        "\n",
        "    # Convert the list of byte integers to a hex string\n",
        "    final_key_hex = ''.join([format(byte, '02x') for byte in found_key_bytes]) # cite: 85\n",
        "    return final_key_hex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre Download the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://aoi-assignment2.oy.ne.ro:8080/encrypt?user=208009845&difficulty=1\n",
            "Downloaded 10000 traces for each difficulty level up to 1.\n"
          ]
        }
      ],
      "source": [
        "for difficulty in range(1, DIFFICULTY_TO_DOWNLOAD + 1):\n",
        "    download_power_traces(PREFIX_TRACES_FILE_NAME, PREFIX_PLAINTEXT_FILE_NAME, PREFIX_ENCRYPT_URL, AMOUNT_OF_TRACES, difficulty)\n",
        "print(f\"Downloaded {AMOUNT_OF_TRACES} traces for each difficulty level up to {DIFFICULTY_TO_DOWNLOAD}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finding the Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_if_correct_key(key: str, url: str = PREFIX_ENCRYPT_URL, difficulty: int = DIFFICULTY):\n",
        "    url = f\"{url}&difficulty={difficulty}&key={key}\"\n",
        "    response = requests.get(url)\n",
        "    return bool(response.text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "files\\plaintext_208009845_1_10000.txt files\\traces_208009845_1_10000.txt\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "cannot fit 'int' into an index-sized integer",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(plaintext_filename, traces_filename)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#means, variances = getMeansVariances()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m key = \u001b[43mfind_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaintext_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraces_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m elapsed_time = time.time() - start_time\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m elapsed_time > TIME_LIMIT:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mfind_key\u001b[39m\u001b[34m(plaintext_filename, traces_filename, amount_of_traces, key_length)\u001b[39m\n\u001b[32m     35\u001b[39m intermediate_val = plaintexts[i][byte_index] ^ guess_k\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Apply S-box (first round output)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m sbox_output = \u001b[43mAesSbox\u001b[49m\u001b[43m[\u001b[49m\u001b[43mintermediate_val\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# cite: 96, 97, 98\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Calculate Hamming Weight\u001b[39;00m\n\u001b[32m     41\u001b[39m predicted_ham_weights.append(hamming_weight(sbox_output))\n",
            "\u001b[31mIndexError\u001b[39m: cannot fit 'int' into an index-sized integer"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "difficulty = DIFFICULTY\n",
        "while True:\n",
        "    plaintext_filename =rf\"files\\{PREFIX_PLAINTEXT_FILE_NAME}_{difficulty}_{AMOUNT_OF_TRACES}.txt\"\n",
        "    traces_filename = rf\"files\\{PREFIX_TRACES_FILE_NAME}_{difficulty}_{AMOUNT_OF_TRACES}.txt\"\n",
        "    print(plaintext_filename, traces_filename)\n",
        "    #means, variances = getMeansVariances()\n",
        "    key = find_key(plaintext_filename, traces_filename)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if elapsed_time > TIME_LIMIT:\n",
        "        print(f\"Total runtime: {last_elapsed_time} seconds\")\n",
        "    if not check_if_correct_key(key):\n",
        "        continue\n",
        "    print(f\"{USER},{key},{DIFFICULTY}\")\n",
        "    difficulty += 1\n",
        "    last_elapsed_time = elapsed_time"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
